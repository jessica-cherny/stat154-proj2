---
title: "R Notebook"
output: html_notebook
---

```{r}
# classifier needs to be a character string
# trainFeats will be a vector of train features, such as c("x", "y")
# trainLabels is the binary response variable, as a string
# foldsK is the number of folds in CV, an integer
# lossFunc is a function call
# training is the training data frame where all features and labels come from


# lossfunc can be cv error, hinge loss, logistic loss
CVgeneric <- function(classifier, trainFeats, trainLabels, foldsK, lossFunc, training) {
  set.seed(154)
  folds <- createFolds(training[,trainLabels], k = foldsK)
  acc_folds <- c()
  formula <- as.formula(paste(trainLabels, "~", paste(trainFeats, collapse = "+"), sep = ""))
  for (i in 1:length(folds)){
    if (classifier == 'randomForest') {
    model <- randomForest(formula, data=training[-c(folds[[i]]),], importance = TRUE)
    pred_class <- predict(model, newdata = training[c(folds[[i]]),], type = 'class')
    loss <- lossFunc(actual = as.numeric(as.character(training[c(folds[[i]]), trainLabels])), 
                     predicted = as.numeric(as.character(pred_class)))
    acc_folds[paste("fold", i, sep="")] <- 1- loss
    } else {
    model <- train(formula, data=training[-c(folds[[i]]),], method=classifier)
    pred_class <- predict(model, newdata = training[c(folds[[i]]),], "raw")
    loss <- lossFunc(actual = as.numeric(as.character(training[c(folds[[i]]), trainLabels])), 
                     predicted = as.numeric(as.character(pred_class)))
    acc_folds[paste("fold", i, sep="")] <- 1 - loss}
  }
  return (acc_folds)
}
```

```{r}
# Example
CVgeneric(classifier = "glm" , trainFeats = c("CORR","SD","NDAI","rad_angle_AN"), trainLabels = "label", foldsK = 5, lossFunc = mse, training = train_temp_new)
```

